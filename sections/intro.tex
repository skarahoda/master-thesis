\chapter{INTRODUCTION}
\label{sec:Intro}

A {\em synchronizing word} $w$ for an automaton $\mathcal{A}$ is a sequence of inputs such that no matter at which state $\mathcal{A}$ currently is, if $w$ is applied, $\mathcal{A}$ is brought to a particular state. Such words do not necessarily exist for every automaton. An automaton with a synchronizing word is called {\em synchronizing}.

Synchronizing automata have practical applications in many areas. For example in model based testing \cite{Broy05} and in particular, for finite state machine based testing \cite{LY96}, test sequences are designed to be applied at a designated state. The implementation under test can be brought to the desired state by using a synchronizing word. Similarly, synchronizing words are used to generate test cases for synchronous circuits with no reset feature \cite{Cho93}. Even when a reset feature is available, there are cases where reset operations are too costly to be applied. In these cases, a synchronizing word can be used as a compound reset operation \cite{JUY15}. Natarajan \cite{Natarajan86} puts forward another surprising application area, part orienters, where a part moving on a conveyor belt is oriented into a particular orientation by the obstacles placed along the conveyor belt. The part is in some unknown orientation initially, and the obstacles should be placed in such a way that, regardless of the initial orientation of the part, the sequence of pushes performed by the obstacles along the way makes sure that the part is in a unique orientation at the end. Volkov \cite{Volkov08} presents more examples for the applications of synchronizing words together with a survey of theoretical results related to synchronizing automata.

\pagebreak

As noted above, not every automaton is synchronizing. As shown by Eppstein \cite{Eppstein90}, checking if an automaton with $n$ states and $p$ letters is synchronizing can be performed in time $O(pn^2)$. For a synchronizing automaton, finding a shortest synchronizing word (which is not necessarily unique) is of interest from a practical point of view for obvious reasons (e.g. shorter test sequences in testing applications, or fewer number of obstacles for parts orienters, etc.).

The problem of finding the length of a shortest synchronizing word for a synchronizing automaton has been a very interesting problem from a theoretical point of view as well. This problem is known to be \NPHARD\ \cite{Eppstein90}, and \coNPHARD\ \cite{OU10}. The methods to find shortest synchronizing words scale up to a couple of hundreds of states in practice at most \cite{KKS15}. Another interesting aspect of this problem is the following. It is conjectured that for a synchronizing automaton with $n$ states, the length of the shortest synchronizing sequence is at most $(n-1)^2$, which is known as the {\em \v{C}ern\'y Conjecture} in the literature \cite{Cerny64, Cerny71}. Posed half a century ago, the conjecture is still open and claimed to be one of the longest standing open problems in automata theory. Until recently, the best upper bound known for the length of a synchronizing word is $(n^3 - n)/6$ by Pin \cite{Pin83}. Currently, the best bound is slightly better than $\frac{114}{685}n^3 + O(n^2)$ as provided by Szyku{\l}a \cite{Szykula17}.

Due to the hardness results given above for finding shortest synchronizing words, there exist heuristics in the literature, known as {\em synchronizing heuristics}, to compute short synchronizing words. Among such heuristics are 
\greedyAlgo\ by Eppstein \cite{Eppstein90}, \textsc{Cycle} by Trahtman \cite{Trahtman04}, 
\textsc{SynchroP} by Roman \cite{Roman09}, \textsc{SynchroPL} by Roman \cite{Roman09},  
\textsc{FastSynchro} by Kud{\l}acik et al. \cite{Roman12}, and forward and backward synchronization heuristics by Roman and Szyku{\l}a \cite{RS15}. In terms of complexity, these heuristics are ordered as follows: \textsc{Greedy}/\textsc{Cycle} with time complexity $O(n^3+pn^2)$, \textsc{FastSynchro} with time complexity $O(pn^4)$, and finally \textsc{SynchroP}/\textsc{SynchroPL} with time complexity $O(n^5+pn^2)$ \cite{Roman09,Roman12}, where $n$ is the number of states and $p$ is the size of the alphabet. This ordering with respect to the worst case time complexity is the same if the actual  performance of the algorithms are considered (see for example \cite{Roman12,RS15} for experimental comparison of the performance of these algorithms).

\pagebreak

The fastest synchronizing heuristics, \textsc{Greedy} and \textsc{Cycle}, are also the earliest heuristics that appeared in the literature. Therefore \textsc{Greedy} and \textsc{Cycle} are usually considered as a baseline to evaluate the quality and the performance of new heuristics. Newer heuristics do generate shorter synchronizing words, but by performing a more complex analysis, which implies a substantial increase on the runtime. The time performance of \textsc{Greedy} and \textsc{Cycle} are unmatched to date.  

All synchronizing heuristics consist of a preprocessing phase, followed by reset word generation phase. As presented in this thesis, our initial experiments revealed that the preprocessing phase dominates the runtime of the overall algorithm for \textsc{Greedy}. We also discovered that the preprocessing computes more information than reset word generation phase needs. To speed up \greedyAlgo\ without sacrificing the
quality of the synchronizing words generated by the heuristic, we propose two main techniques that speedup \greedyAlgo . First, we focused on parallelization of \textsc{Greedy}. Second, we propose a lazy execution of the preprocessing, by postponing the preparation of the required information until it is to be used in the reset word generation phase. We suggest other algorithmic enhancements as well for the implementation of the heuristics. 

To the best of our knowledge, this is the first work towards parallelization of  synchronizing heuristics. Although, a parallel approach for constructing a synchronizing sequence for partial automata\footnote{Please see Section~\ref{sec:Preliminaries} for the definition of a partial automaton.} has been proposed in \cite{Uraz}, it is not exact (in the sense that it may fail to find a synchronizing sequence even if at least one exists). Furthermore, it is not a polynomial time algorithm.

The rest of the thesis is organized as follows: In Section~\ref{sec:Preliminaries}, the notation used in the thesis is introduced, and synchronizing sequences are formally defined. We give the details of Eppstein's {\sc Greedy} construction algorithm in Section \ref{sec:greedy}. The parallelization approach together with the implementation details are described in Section \ref{sec:parallel}. Section \ref{sec:speedup}, algorithmic optimizations which avoid most of the redundant computations in the original heuristic are introduced. The results in these two sections are published in~\cite{KEK16} and~\cite{SpeedingUptheFastest}, respectively. Section \ref{sec:results} presents the experimental results and Section~\ref{sec:conclusion} concludes the thesis.